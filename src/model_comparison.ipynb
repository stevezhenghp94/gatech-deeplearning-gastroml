{"cells":[{"cell_type":"markdown","metadata":{"id":"EQ83B8T2nC47"},"source":["# Model comparison\n","## Meta pretrain model vs models train on different datasets\n","\n","#### Meta model was train on the 1M recipe dataset\n","#### Custom models were train on Kaggle Food Ingredients and Recipes Dataset with Images\n","https://www.kaggle.com/datasets/pes12017000148/food-ingredients-and-recipe-dataset-with-images?select=Food+Images"]},{"cell_type":"markdown","metadata":{"id":"bGComgkEnC5C"},"source":["#### Configure drive and import libraries\n","\n","The notebook is run on colab, the following command will mount the project folder"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22877,"status":"ok","timestamp":1702076943683,"user":{"displayName":"juan rodrigo reyes","userId":"17113265916897419484"},"user_tz":300},"id":"zQ8q7NO1nC5D","outputId":"93a277a4-1f6a-42b3-ee2d-ebb8755ec4e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/Othercomputers/Mi portátil/gastroml/src\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","# cd to a folder in your Drive - in my case is this route\n","%cd '/content/drive/Othercomputers/Mi portátil/gastroml/src'"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":11525,"status":"ok","timestamp":1702076969473,"user":{"displayName":"juan rodrigo reyes","userId":"17113265916897419484"},"user_tz":300},"id":"TaD4mOm7nC5G"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import pandas as pd\n","import numpy as np\n","import os\n","from args import get_parser\n","import pickle\n","from model import get_model\n","from torchvision import transforms\n","from utils.output_utils import prepare_output\n","from PIL import Image\n","import time\n","from build_vocab import Vocabulary\n","\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":210,"status":"ok","timestamp":1702076971400,"user":{"displayName":"juan rodrigo reyes","userId":"17113265916897419484"},"user_tz":300},"id":"LPfV_q0onC5I"},"outputs":[],"source":["# code will run in gpu if available and if the flag is set to True, else it will run on cpu\n","use_gpu = True\n","device = torch.device('cuda' if torch.cuda.is_available() and use_gpu else 'cpu')\n","map_loc = None if torch.cuda.is_available() and use_gpu else 'cpu'"]},{"cell_type":"markdown","metadata":{"id":"q_D-iyOPnC5J"},"source":["# Model and vocab definitions and paths"]},{"cell_type":"markdown","metadata":{"id":"-UJV73EInC5K"},"source":["### Constants definitions"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":218,"status":"ok","timestamp":1702076974445,"user":{"displayName":"juan rodrigo reyes","userId":"17113265916897419484"},"user_tz":300},"id":"wiMlniOMnC5M"},"outputs":[],"source":["params_dict = {}\n","model_list = [\"model\", \"modeResnet18\", \"modeResnet101\", \"modelResnet152\", \"modelMeta\"]\n","model_dict = {\"model\":\"Resnet50\", \"modeResnet18\":\"Resnet18\", \"modeResnet101\":\"Resnet101\", \"modelResnet152\":\"Resnet152\",\"modelMeta\":\"Meta\"}\n","model_dir = \"../checkpoints/inversecooking\"\n","data_dir = '../data'\n","vocab_ings_dict = {\"model\":\"recipe1m_vocab_ingrs\", \"modeResnet18\":\"recipe1m_vocab_ingrs\", \"modeResnet101\":\"recipe1m_vocab_ingrs\", \"modelResnet152\":\"recipe1m_vocab_ingrs\",\"modelMeta\":\"ingr_vocab_meta\"}\n","vocab_inst_dict = {\"model\":\"recipe1m_vocab_toks\", \"modeResnet18\":\"recipe1m_vocab_toks\", \"modeResnet101\":\"recipe1m_vocab_toks\", \"modelResnet152\":\"recipe1m_vocab_toks\",\"modelMeta\":\"instr_vocab_meta\"}"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":39296,"status":"ok","timestamp":1702077078701,"user":{"displayName":"juan rodrigo reyes","userId":"17113265916897419484"},"user_tz":300},"id":"V3bBnzM0nC5N"},"outputs":[],"source":["train_image_folder = os.path.join(\"../Kaggle data/images\", 'train')\n","test_image_folder = os.path.join(\"../Kaggle data/images\", 'test')\n","val_image_folder = os.path.join(\"../Kaggle data/images\", 'val')\n","demo_image_folder = os.path.join(\"../data\", 'demo_imgs')\n","\n","\n","train_imgs = os.listdir(train_image_folder)\n","test_imgs = os.listdir(test_image_folder)\n","val_imgs = os.listdir(val_image_folder)\n","demo_imgs = os.listdir(val_image_folder)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1702060672775,"user":{"displayName":"juan rodrigo reyes","userId":"17113265916897419484"},"user_tz":300},"id":"XIVVwjp3nZEl","outputId":"b2c4e8ac-c617-4f50-b9cb-fe38509d4b04"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1978"]},"metadata":{},"execution_count":18}],"source":["len(val_imgs)"]},{"cell_type":"markdown","metadata":{"id":"b1NuwivvnC5O"},"source":["### Functions to get vocab, load_model based on model name"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1702060672775,"user":{"displayName":"juan rodrigo reyes","userId":"17113265916897419484"},"user_tz":300},"id":"y2GueXhnnC5O"},"outputs":[],"source":["def get_vocab_pickle(model_name):\n","    \"\"\"Function to get the vocab pickle file for a given model name.\n","    If the model name is \"modelMeta\", the function will return the meta vocab pickle files.\n","    The meta vocab pickle files are pretrained and were downloaded from the original repo.\n","    url: https://github.com/facebookresearch/inversecooking\n","    If the model name is \"model\", the function will return the recipe1m vocab pickle files.\n","    The vocab files were created using the build_vocab.py script with the kaggle dataset.\n","\n","    Args:\n","        model_name (str): Model name. It can be \"model\", \"modelMeta\", \"modeResnet18\", \"modeResnet101\", \"modelResnet152\"\n","\n","    Returns:\n","        vocab, ingrs_vocab, ingr_vocab_size, instrs_vocab_size, output_dim: vocab pickle files and vocab sizes\n","    \"\"\"\n","    vocab_ing_name = vocab_ings_dict[model_name]\n","    vocab_inst_name = vocab_inst_dict[model_name]\n","    if model_name != \"modelMeta\":\n","        ing_vocab_name = \"ingr_vocab\"\n","        vocab_name = \"instr_vocab\"\n","        ingrs_vocab = pickle.load(open(os.path.join(data_dir, f'{vocab_ing_name}.pkl'), 'rb'))\n","        ingrs_vocab = [min(w, key=len) if not isinstance(w, str) else w for w in ingrs_vocab.idx2word.values()]\n","        vocab = pickle.load(open(os.path.join(data_dir, f'{vocab_inst_name}.pkl'), 'rb')).idx2word\n","\n","    else:\n","        ing_vocab_name = \"ingr_vocab_meta\"\n","        vocab_name = \"instr_vocab_meta\"\n","        ingrs_vocab = pickle.load(open(os.path.join(data_dir, 'ingr_vocab_meta.pkl'), 'rb'))\n","        vocab = pickle.load(open(os.path.join(data_dir, 'instr_vocab_meta.pkl'), 'rb'))\n","\n","    pickle.dump(ingrs_vocab, open(f'../data/f{ing_vocab_name}.pkl', 'wb'))\n","    pickle.dump(vocab, open(f'../data/f{vocab_name}.pkl', 'wb'))\n","\n","    ingr_vocab_size = len(ingrs_vocab)\n","    instrs_vocab_size = len(vocab)\n","    output_dim = instrs_vocab_size\n","    return vocab, ingrs_vocab, ingr_vocab_size, instrs_vocab_size, output_dim"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1702060673374,"user":{"displayName":"juan rodrigo reyes","userId":"17113265916897419484"},"user_tz":300},"id":"RFa9KRpznC5P"},"outputs":[],"source":["# for model_name in model_list:\n","#     print(model_name)\n","#     vocab, ingrs_vocab, ingr_vocab_size, instrs_vocab_size, output_dim = get_vocab_pickle(model_name)\n","#     print(ingr_vocab_size, instrs_vocab_size, output_dim)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1702060673817,"user":{"displayName":"juan rodrigo reyes","userId":"17113265916897419484"},"user_tz":300},"id":"DEhTSGk4nC5Q"},"outputs":[],"source":["import sys; sys.argv=['']; del sys\n","def load_model(model_name, model_dir, map_loc):\n","    \"\"\"Function to load a model given a model name, a model directory and a map location.\n","    The map location is the device where the model will be loaded.\n","    The model directory is the directory where the model is stored.\n","    The model name is the name of the model to be loaded.\n","    The meta model is the model trained with the meta vocab pickle files and\n","    downloaded from the original repo. This model was trained with the original dataset.\n","\n","    Args:\n","        model_name (str): Model name. It can be \"model\", \"modelMeta\", \"modeResnet18\", \"modeResnet101\", \"modelResnet152\"\n","        model_dir (str): Folder where the model is stored.\n","        map_loc (str): Device where the model will be loaded. It can be \"cpu\" or \"cuda\"\n","\n","    Returns:\n","        _type_: _description_\n","    \"\"\"\n","    # print(model_name)\n","    vocab, ingrs_vocab, ingr_vocab_size, instrs_vocab_size, output_dim = get_vocab_pickle(model_name)\n","    args = get_parser()\n","    args.maxseqlen = 15\n","    args.ingrs_only=False\n","    # if metal model, use default arguments for image model\n","    if model_name != \"modelMeta\":\n","        args.image_model = model_dict[model_name].lower()\n","    model = get_model(args, ingr_vocab_size, instrs_vocab_size)\n","    model_path = os.path.join(model_dir, model_name+'/checkpoints/modelbest.ckpt')\n","    # print(model_path)\n","    model.load_state_dict(torch.load(model_path, map_location=map_loc))\n","    model.to(device)\n","    model.eval()\n","    model.ingrs_only = False\n","    model.recipe_only = False\n","\n","    return model, vocab, ingrs_vocab, ingr_vocab_size, instrs_vocab_size, output_dim"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1702060673817,"user":{"displayName":"juan rodrigo reyes","userId":"17113265916897419484"},"user_tz":300},"id":"QOkVA6RonC5R"},"outputs":[],"source":["# for model_name in model_list:\n","#     print(model_name)\n","#     model = load_model(model_name, model_dir, map_loc)\n","#     print(model)\n"]},{"cell_type":"markdown","metadata":{"id":"leVNm8-SnC5S"},"source":["### get predictions on the datasets"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1702060673817,"user":{"displayName":"juan rodrigo reyes","userId":"17113265916897419484"},"user_tz":300},"id":"1W3z9fFPnC5S"},"outputs":[],"source":["transf_list_batch = []\n","transf_list_batch.append(transforms.ToTensor())\n","transf_list_batch.append(transforms.Normalize((0.485, 0.456, 0.406),\n","                                              (0.229, 0.224, 0.225)))\n","to_input_transf = transforms.Compose(transf_list_batch)\n","\n","greedy = True\n","beam =-1\n","temperature = 1.0\n","numgens = 1\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"gEi3i0X4zCTG","executionInfo":{"status":"ok","timestamp":1702061944111,"user_tz":300,"elapsed":2,"user":{"displayName":"juan rodrigo reyes","userId":"17113265916897419484"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":383,"status":"ok","timestamp":1702061999156,"user":{"displayName":"juan rodrigo reyes","userId":"17113265916897419484"},"user_tz":300},"id":"PWWarCbMnC5T"},"outputs":[],"source":["def generate_predictions(model_name,dataset,model_dir, map_loc):\n","    \"\"\"Function to generate predictions given a model name and a dataset.\n","    The model name is the name of the model to be loaded.\n","    The dataset is the dataset to be used to generate the predictions.\n","    The function will return a list of lists with the following structure:\n","    [dataset, model_name, img_file, greedy,beam, outs['title'], outs['ingrs'], outs['recipe']]\n","    The list of lists will contain the dataset name, the model name, the image file name,\n","    the greedy flag, the beam size, the title, the ingredients and the recipe.\n","\n","    Args:\n","        model_name (str): Model name. It can be \"model\", \"modelMeta\", \"modeResnet18\", \"modeResnet101\", \"modelResnet152\"\n","        dataset (str): Dataset to be used. It can be \"train\", \"test\" or \"val\"\n","    \"\"\"\n","    t = time.time()\n","    if dataset == \"train\":\n","        set_imgs = train_imgs\n","        image_folder = train_image_folder\n","    elif dataset == \"test\":\n","        set_imgs = test_imgs\n","        image_folder = test_image_folder\n","    elif dataset == \"val\":\n","        set_imgs = val_imgs\n","        image_folder = val_image_folder\n","    else:\n","        print(\"Dataset not valid\")\n","        return None\n","\n","    model, vocab, ingrs_vocab, ingr_vocab_size, instrs_vocab_size, output_dim = load_model(model_name, model_dir, map_loc)\n","    predictions = []\n","    for img_num, img_file in enumerate(set_imgs):\n","        image_path = os.path.join(image_folder, img_file)\n","        image = Image.open(image_path).convert('RGB')\n","\n","        transf_list = []\n","        transf_list.append(transforms.Resize(256))\n","        transf_list.append(transforms.CenterCrop(224))\n","        transform = transforms.Compose(transf_list)\n","\n","        image_transf = transform(image)\n","        image_tensor = to_input_transf(image_transf).unsqueeze(0).to(device)\n","        # plt.imshow(image_transf)\n","        # plt.axis('off')\n","        # plt.show()\n","        # plt.close()\n","\n","        pred_valid = False\n","        counter_not_valid = 0\n","\n","        while not pred_valid:\n","            with torch.no_grad():\n","                outputs = model.sample(image_tensor, greedy=greedy,\n","                                    temperature=temperature, beam=beam, true_ingrs=None)\n","\n","            ingr_ids = outputs['ingr_ids'].cpu().numpy()\n","            recipe_ids = outputs['recipe_ids'].cpu().numpy()\n","\n","            outs, valid = prepare_output(recipe_ids[0], ingr_ids[0], ingrs_vocab, vocab)\n","            # check if output is valid, if not try again until a valid output is found\n","            # or try again 5 times and then return the last valid output\n","            if valid['is_valid'] or counter_not_valid < 5:\n","\n","                predictions.append([dataset, model_name, model_dict[model_name], img_file, greedy,beam, outs['title'], outs['ingrs'], outs['recipe']])\n","\n","                pred_valid=True\n","\n","            else:\n","                pass\n","                print (\"Not a valid recipe!\")\n","                print (\"Reason: \", valid['reason'])\n","                print( outs['title'], outs['ingrs'])\n","                counter_not_valid += 1\n","        if img_num % 100 == 0 and img_num >0:\n","            print(img_num)\n","            print(\"Elapsed time:\", time.time() -t)\n","            columns = ['dataset', 'model_name', 'conv_model', 'img_file', 'greedy','beam', 'title', 'ingrs', 'recipe']\n","            back_up_predictions = pd.DataFrame(predictions, columns=columns)\n","            back_up_predictions.to_csv(f'../data/predictions/{dataset}_{model_name}_{img_num}.csv', index=False)\n","\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VsLw2EbYnC5T","outputId":"9d4b4e40-4b0a-40aa-aa09-b8b3e48d1faf"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["val\n","model\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["100\n","Elapsed time: 426.6175935268402\n","200\n","Elapsed time: 826.4734308719635\n","300\n","Elapsed time: 1228.666065454483\n","400\n","Elapsed time: 1627.2652966976166\n","500\n","Elapsed time: 2025.7136301994324\n","600\n","Elapsed time: 2427.1810081005096\n","700\n","Elapsed time: 2827.6533122062683\n","800\n","Elapsed time: 3226.779386997223\n","900\n","Elapsed time: 3625.9108011722565\n","1000\n","Elapsed time: 4027.3637297153473\n","1100\n","Elapsed time: 4426.787456989288\n","1200\n","Elapsed time: 4828.129145622253\n","1300\n","Elapsed time: 5226.799397945404\n","1400\n","Elapsed time: 5638.900363206863\n","1500\n","Elapsed time: 6047.53696346283\n","1600\n","Elapsed time: 6448.778054714203\n","1700\n","Elapsed time: 6851.248430728912\n","1800\n","Elapsed time: 7252.175611495972\n","1900\n","Elapsed time: 7661.599985361099\n","modeResnet18\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 66.0MB/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n"]},{"output_type":"stream","name":"stdout","text":["100\n","Elapsed time: 337.228307723999\n","200\n","Elapsed time: 662.2291955947876\n","300\n","Elapsed time: 980.4937329292297\n","400\n","Elapsed time: 1297.946503162384\n","500\n","Elapsed time: 1615.2291541099548\n","600\n","Elapsed time: 1929.2445261478424\n","700\n","Elapsed time: 2238.1677720546722\n","800\n","Elapsed time: 2542.2405710220337\n","900\n","Elapsed time: 2848.3263483047485\n","1000\n","Elapsed time: 3155.9454395771027\n","1100\n","Elapsed time: 3464.727267742157\n","1200\n","Elapsed time: 3772.4022731781006\n","1300\n","Elapsed time: 4080.3524177074432\n","1400\n","Elapsed time: 4389.417931556702\n","1500\n","Elapsed time: 4700.330945014954\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-28-6cdaf3fdd736>\", line 5, in <cell line: 1>\n","    predictions = generate_predictions(model_name,dataset,model_dir, map_loc)\n","  File \"<ipython-input-27-4c7643db2e89>\", line 32, in generate_predictions\n","    image = Image.open(image_path).convert('RGB')\n","  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3227, in open\n","    fp = builtins.open(filename, \"rb\")\n","OSError: [Errno 107] Transport endpoint is not connected: '../Kaggle data/images/val/thyme-walnut-sandies.jpg'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-28-6cdaf3fdd736>\", line 5, in <cell line: 1>\n","    predictions = generate_predictions(model_name,dataset,model_dir, map_loc)\n","  File \"<ipython-input-27-4c7643db2e89>\", line 32, in generate_predictions\n","    image = Image.open(image_path).convert('RGB')\n","  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3227, in open\n","    fp = builtins.open(filename, \"rb\")\n","OSError: [Errno 107] Transport endpoint is not connected: '../Kaggle data/images/val/thyme-walnut-sandies.jpg'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-28-6cdaf3fdd736>\", line 5, in <cell line: 1>\n","    predictions = generate_predictions(model_name,dataset,model_dir, map_loc)\n","  File \"<ipython-input-27-4c7643db2e89>\", line 32, in generate_predictions\n","    image = Image.open(image_path).convert('RGB')\n","  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3227, in open\n","    fp = builtins.open(filename, \"rb\")\n","OSError: [Errno 107] Transport endpoint is not connected: '../Kaggle data/images/val/thyme-walnut-sandies.jpg'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n","    self.showtraceback()\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n","    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"]}],"source":["for dataset in [\"val\",\"train\", \"test\"]:\n","    print(dataset)\n","    for model_name in model_list:\n","        print(model_name)\n","        predictions = generate_predictions(model_name,dataset,model_dir, map_loc)\n","        columns = ['dataset', 'model_name', 'conv_model', 'img_file', 'greedy','beam', 'title', 'ingrs', 'recipe']\n","        predictions = pd.DataFrame(predictions, columns=columns)\n","        predictions.to_csv(f'../data/predictions/{dataset}_{model_name}.csv', index=False)"]},{"cell_type":"markdown","source":["### Create metrics"],"metadata":{"id":"p3CKS7hAUJ8s"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8mmI9YoDn7eK"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_QyVE8oBn7o_"},"outputs":[],"source":["!pip install -U sentence_transformers"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}